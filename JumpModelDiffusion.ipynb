{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0MefTMgaOdx"
      },
      "source": [
        "###Setting up our Random Number Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSAktldWUdvg",
        "outputId": "03e8b7b3-8474-4a9a-eb39-4182d79b451d"
      },
      "outputs": [],
      "source": [
        "%%writefile random_number_gen.pyx\n",
        "\n",
        "import numpy as np\n",
        "cimport numpy as np\n",
        "import scipy\n",
        "\n",
        "cimport scipy\n",
        "from cpython.mem cimport PyMem_Malloc, PyMem_Free\n",
        "cdef class RandomNumberGen:\n",
        "    cdef unsigned long long mod1, a1, a2, a3, mod2, b1, b2, b3, x0, x1, x2\n",
        "    cdef double multiplicator\n",
        "    cdef bint LHS\n",
        "\n",
        "    def __cinit__(self):\n",
        "        self.mod1 = 2**31 - 1\n",
        "        self.a1 = 0\n",
        "        self.a2 = 63308\n",
        "        self.a3 = -183326\n",
        "        self.mod2 = 2145483479\n",
        "        self.b1 = 86098\n",
        "        self.b2 = 0\n",
        "        self.b3 = -539608\n",
        "        self.x0=17  ## Define Seed Here\n",
        "        self.x1=37  ## Define Seed Here\n",
        "        self.x2=13337 ## Define Seed Here\n",
        "        self.multiplicator=4.656612875245797e-10\n",
        "        self.LHS=True\n",
        "\n",
        "    cpdef double Scrambled_Random(self):\n",
        "        cdef unsigned long long Component1, Component2, Combined, y\n",
        "        Component1 = (self.x2 * self.a1 + self.x1 * self.a2 + self.x0 * self.a3) % self.mod1\n",
        "        Component2 = (self.x2 * self.b1 + self.x1 * self.b2 + self.x0 * self.b3) % self.mod2\n",
        "        Combined = (Component1 - Component2) % self.mod1\n",
        "        if Combined < 0:\n",
        "            Combined += self.mod1\n",
        "        y = Combined\n",
        "        y ^= (y << 17)  # Parentheses to avoid type mismatch\n",
        "        y ^= (y >> 15)  # Parentheses to avoid type mismatch\n",
        "        y ^= (y << 26)  # Parentheses to avoid type mismatch\n",
        "        y = y % self.mod1\n",
        "        self.x2, self.x1, self.x0 = y, self.x2, self.x1\n",
        "\n",
        "        return y*self.multiplicator\n",
        "\n",
        "    cpdef np.ndarray generate_matrix(self, int rows,int cols,LHS=True):\n",
        "        cdef np.ndarray[np.double_t, ndim=2] matrix = np.zeros((rows, cols), dtype=np.double)\n",
        "        cdef Py_ssize_t i, j\n",
        "        if LHS:\n",
        "            for i in range(rows):\n",
        "                for j in range(cols):\n",
        "                    matrix[i, j] = i/rows+self.Scrambled_Random()/rows\n",
        "            for j in range(cols):\n",
        "                matrix[:, j] = np.random.permutation(matrix[:, j])\n",
        "            return matrix\n",
        "        else:\n",
        "            for i in range(rows):\n",
        "                for j in range(cols):\n",
        "                    matrix[i, j] = self.Scrambled_Random()\n",
        "            return matrix\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        return matrix\n",
        "    cpdef np.ndarray inverse_transform(self, np.ndarray input_matrix,np.ndarray CDF_matrix,np.ndarray X_vector):\n",
        "        cdef np.ndarray[np.double_t, ndim=2] matrix = np.zeros((input_matrix.shape[0], input_matrix.shape[1]), dtype=np.double)\n",
        "        cdef Py_ssize_t i, j\n",
        "        cdef double u\n",
        "        for i in range(input_matrix.shape[0]):\n",
        "            for j in range(input_matrix.shape[1]):\n",
        "                u = input_matrix[i, j]\n",
        "                matrix[i, j] = np.interp(u, CDF_matrix, X_vector)\n",
        "\n",
        "        return matrix\n",
        "    cpdef np.ndarray generate_poisson(self,int rows,int cols,double lambda_,bint Antithetic=True):\n",
        "        cdef np.ndarray[np.double_t, ndim=2] matrix = np.zeros((rows, cols), dtype=np.double)\n",
        "        cdef Py_ssize_t  i, j\n",
        "        cdef double comp=np.exp(-lambda_)\n",
        "        cdef np.ndarray[np.double_t,ndim=2] Sample\n",
        "        cdef double u,u2,k1,k2,comp2,Prob\n",
        "        if Antithetic:\n",
        "            sample=self.generate_matrix(rows//2,cols)\n",
        "            for i in range(rows//2):\n",
        "                for j in range(cols):\n",
        "                    comp2=comp\n",
        "                    Prob=comp\n",
        "                    u=sample[i,j]\n",
        "                    u2=1-u\n",
        "                    k1=0\n",
        "                    k2=0\n",
        "                    \n",
        "                    while u>comp2:\n",
        "                        k1=k1+1\n",
        "                        Prob=lambda_/k1*Prob\n",
        "                        comp2=comp2+Prob\n",
        "                    comp2=comp\n",
        "                    Prob=comp\n",
        "                    while u2>comp2:  \n",
        "                        \n",
        "                        k2=k2+1\n",
        "                        Prob=lambda_/k2*Prob\n",
        "                        comp2=comp2+Prob\n",
        "                    matrix[int(2*i),j]=k1\n",
        "                    matrix[int(2*i+1),j]=k2\n",
        "\n",
        "        else:\n",
        "            sample=self.generate_matrix(rows,cols)\n",
        "            for i in range(rows):\n",
        "                for j in range(cols):\n",
        "                    comp2=comp\n",
        "                    Prob=comp\n",
        "                    u=sample[i,j]\n",
        "                    k1=0\n",
        "                    while u>comp2:\n",
        "                        k1+=1\n",
        "                        Prob=lambda_/k1*Prob\n",
        "                        comp2=comp2+Prob\n",
        "                    matrix[i,j]=k1\n",
        "        return matrix\n",
        "    cpdef np.ndarray generate_normal(self,int rows, int cols,double loc=0,double scale=1,Antithetic=True):\n",
        "        cdef np.ndarray[np.double_t, ndim=2] matrix = np.zeros((rows, cols), dtype=np.double)\n",
        "        cdef int x\n",
        "        if Antithetic:\n",
        "            x=rows//2\n",
        "        else:\n",
        "            x=rows\n",
        "\n",
        "        matrix=scipy.stats.norm.ppf(self.generate_matrix(x,cols))\n",
        "\n",
        "        if Antithetic:\n",
        "            matrix=np.concatenate([matrix,-matrix])\n",
        "        matrix=loc*np.ones((rows,cols))+scale*matrix\n",
        "        return matrix\n",
        "\n",
        "\n",
        "    cpdef np.ndarray generate_double_exponential(self,int rows, int cols,double p, double eta1,double eta2,Antithetic=True):\n",
        "        cdef double q=1-p\n",
        "        cdef np.ndarray U,negU,PosSamp,NegSamp,AntPosSamp,AntNegSamp,Ou1,Out2\n",
        "        if Antithetic:\n",
        "            U=self.generate_matrix(rows//2,cols)\n",
        "            PosSamp=(1/eta2)*np.log((1/q)*U)\n",
        "            NegSamp=-(1/eta1)*np.log((1/p)*(np.ones((rows//2,cols))-U))\n",
        "            Out1=np.where(U<p*np.ones((rows//2,cols)),PosSamp,NegSamp)\n",
        "            negU=np.ones((rows//2,cols))-U\n",
        "            AntPosSamp=(1/eta2)*np.log((1/q)*negU)\n",
        "            AntNegSamp=(1/eta1)*np.log((1/p)*(np.ones((rows//2,cols))-negU))\n",
        "            Out2=np.where(negU<p*np.ones((rows//2,cols)),AntPosSamp,AntNegSamp)\n",
        "            return np.concatenate([Out1,Out2])\n",
        "        else:\n",
        "            U=self.generate_matrix(rows,cols)\n",
        "            PosSamp=(1/eta2)*np.log((1/q)*U)\n",
        "            NegSamp=-(1/eta1)*np.log((1/p)*(np.ones((rows,cols))-U))\n",
        "            Out1=np.where(U<p*np.ones((rows,cols)),PosSamp,NegSamp)\n",
        "            return Out1\n",
        "    cpdef np.ndarray generate_CGMY_Ylessthan1(self,int rows,int cols,double C,double G,double M,double Y):\n",
        "        cdef np.ndarray[np.double_t, ndim=2] matrix = self.generate_matrix(rows,cols)\n",
        "        \n",
        "        p=G**Y/(G**Y+M**Y)\n",
        "        q=1-p\n",
        "        matrix=np.where(matrix<p,-scipy.special.gammainccinv(-Y,matrix/p)/G,scipy.special.gammaincinv(-Y,(matrix-p)/q)/M) ## we only have the inverse of regularized so we divide by gamma(-y) in the incomplete gamma functions\n",
        "        return matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXVxLqPYUy0k",
        "outputId": "e8211dc6-68df-47cd-9e3f-458af38231e9"
      },
      "outputs": [],
      "source": [
        "!cython --cplus random_number_gen.pyx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OChf9LYRVGp1",
        "outputId": "716040c1-b551-4a41-8625-8b40d77bd79f"
      },
      "outputs": [],
      "source": [
        "%%writefile setup.py\n",
        "from setuptools import setup\n",
        "from Cython.Build import cythonize\n",
        "import numpy\n",
        "import scipy\n",
        "setup(\n",
        "    ext_modules=cythonize(\"random_number_gen.pyx\"),\n",
        "    include_dirs=[numpy.get_include(),scipy.get_include()]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SijRX24VJ5G",
        "outputId": "fcdda9f5-9474-4487-edc0-69211eb47a4c"
      },
      "outputs": [],
      "source": [
        "!python setup.py build_ext --inplace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random_number_gen\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "gen=random_number_gen.RandomNumberGen()\n",
        "X=gen.generate_CGMY_Ylessthan1(1000,10,3,5,5,-1.2)\n",
        "plt.hist(X.flatten(),bins=100)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###Comparing RNGs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJsZt0WeQ7XT"
      },
      "outputs": [],
      "source": [
        "class RandomNumberGen():\n",
        "    def __init__(self,seed):\n",
        "        self.mod1=2**31-1\n",
        "        self.a1=0\n",
        "        self.a2=63308\n",
        "        self.a3=-183326\n",
        "        self.mod2=2145483479\n",
        "        self.b1=86098\n",
        "        self.b2=0\n",
        "        self.b3=-539608\n",
        "        self.x0,self.x1,self.x2=seed\n",
        "\n",
        "\n",
        "    def Scrambled_Random(self):\n",
        "        Component1=(self.x2*self.a1+self.x1*self.a2+self.x0*self.a3)%self.mod1\n",
        "        Component2=(self.x2*self.b1+self.x1*self.b2+self.x0*self.a3)%self.mod2\n",
        "        Combined=(Component1-Component2)%self.mod1 ##mod1>mod2\n",
        "        if Combined<0:\n",
        "            Combined+=self.mod1\n",
        "        y=Combined\n",
        "        y^=y<<17\n",
        "\n",
        "\n",
        "        y^=y>>15\n",
        "\n",
        "\n",
        "        y^=y<<26\n",
        "\n",
        "        y=y%self.mod1\n",
        "\n",
        "        self.x2,self.x1,self.x0=y,self.x2,self.x1\n",
        "\n",
        "        return y/self.mod1\n",
        "    def Random(self):\n",
        "        Component1=(self.x2*self.a1+self.x1*self.a2+self.x0*self.a3)%self.mod1\n",
        "        Component2=(self.x2*self.b1+self.x1*self.b2+self.x0*self.a3)%self.mod2\n",
        "        Combined=(Component1-Component2)%self.mod1 ##mod1>mod2\n",
        "        if Combined<0:\n",
        "            Combined+=self.mod1\n",
        "        self.x2,self.x1,self.x0=Combined,self.x2,self.x1\n",
        "        return Combined/self.mod1\n",
        "    def LCG(self):\n",
        "        new=(self.x2*self.a2)%self.mod1\n",
        "        self.x2=new\n",
        "        new=new/self.mod1\n",
        "        return new\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBO-z0tUSe33",
        "outputId": "234b9080-da19-40d2-90fc-0777618ba807"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import random_number_gen\n",
        "RNG2=random_number_gen.RandomNumberGen()\n",
        "RNG=RandomNumberGen((14,17,27))\n",
        "start=time.time()\n",
        "X=np.random.rand(1_000_000)\n",
        "end=time.time()\n",
        "print(\"time taken:\",end-start)\n",
        "start=time.time()\n",
        "X=[RNG.Scrambled_Random() for _ in range(1_000_000)]\n",
        "end=time.time()\n",
        "\n",
        "print(\"time taken:\",end-start)\n",
        "start=time.time()\n",
        "X=RNG2.generate_matrix(1_000_000,1)\n",
        "end=time.time()\n",
        "print(\"time taken:\",end-start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "2Gmne_c2c786",
        "outputId": "dc45c7e5-668b-47dc-8137-4ad58a657acd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(X,bins=2000,density=True)\n",
        "         \n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random_number_gen\n",
        "gen=random_number_gen.RandomNumberGen()\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "import matplotlib.pyplot as plt\n",
        "m=6\n",
        "sample=gen.generate_double_exponential(1_000_000,1,0.5,1,1)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "value,hist,_=plt.hist(sample, bins=150, density=True, alpha=0.5, label='Sample')\n",
        "x = np.arange(-5, 5,0.01)\n",
        "pmf = norm.pdf(x)\n",
        "\n",
        "plt.plot(x, pmf*max(value)/max(pmf), 'r-', label='Poisson Density')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxfBSUvYYlaW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import poisson\n",
        "import numpy as np\n",
        "from random_number_gen import RandomNumberGen\n",
        "from scipy.stats import norm\n",
        "import matplotlib.pyplot as plt\n",
        "# Create an instance of RandomNumberGen\n",
        "rng = RandomNumberGen()\n",
        "range=np.arange(10,5000,30)\n",
        "# Generate two arrays of Poisson random numbers\n",
        "A1=[]\n",
        "A2=[]\n",
        "for i in range:\n",
        "    poisson1 = rng.generate_poisson(i, 10,5,Antithetic=True) ###Both methods contain LHS so it is not surprising that they are similar in performance\n",
        "    poisson2 = rng.generate_poisson(i, 10,5,Antithetic=False)\n",
        "    A1.append(np.abs(np.mean(poisson1)-5))\n",
        "    A2.append(np.abs(np.mean(poisson2)-5))\n",
        "plt.plot(range,A1,label='Antithetic Poisson')\n",
        "plt.plot(range,A2,label='Non Antithetic Poisson')\n",
        "plt.xlabel('Sample Size')\n",
        "plt.ylabel('Sample Mean')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "B1=[]\n",
        "B2=[]\n",
        "\n",
        "for i in range:\n",
        "    normal1_sample=rng.generate_matrix(i,10,LHS=True)\n",
        "    normal2_sample=rng.generate_matrix(i,10,LHS=False)\n",
        "    normal1=norm.ppf(normal1_sample)\n",
        "    normal2=norm.ppf(normal2_sample)\n",
        "    B1.append(np.abs(np.mean(normal1)))\n",
        "    B2.append(np.abs(np.mean(normal2)))\n",
        "plt.plot(range,B1,label='LHS Normal')\n",
        "plt.plot(range,B2,label='Non LHS Normal')\n",
        "plt.xlabel('Sample Size')\n",
        "plt.ylabel('Sample Mean')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "%timeit rng.generate_matrix(1_000_000,1,LHS=True)\n",
        "%timeit rng.generate_matrix(1_000_000,1,LHS=False)\n",
        "# Example usage\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nj9VQc5GYpTc"
      },
      "source": [
        "###CGMY Characteristic function inversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6I4_IZsc6TX",
        "outputId": "78b009bf-8928-4ca7-bbb0-f60f164d7b24"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "0MUmNSp0ldyB",
        "outputId": "64a509b3-5742-4efd-8786-3880b9e29cb7"
      },
      "outputs": [],
      "source": [
        "\n",
        "from scipy.special import gamma,gammaincc\n",
        "import numpy as np\n",
        "import scipy.optimize as optimize\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "import random_number_gen\n",
        "  # Rest of the code...\n",
        "class CGMY():\n",
        "  def __init__(self, C, G, M, Y, t, error):\n",
        "    self.C = C\n",
        "    self.G = G\n",
        "    self.M = M\n",
        "    if Y == int(Y):\n",
        "      self.Y = Y - 0.03  ##to avoid overflow during gamma function evaluation\n",
        "    else:\n",
        "      self.Y = Y\n",
        "    self.t = t\n",
        "    self.error = error\n",
        "\n",
        "  def characteristic_function(self,u,t,increment=[0,0,0,0]):\n",
        "\n",
        "      C,G,M,Y=np.add([self.C,self.G,self.M,self.Y],increment)\n",
        "      return np.exp(t*C*gamma(-Y)*((M-1j*u)**Y-M**Y+(G+1j*u)**Y-G**Y))\n",
        "\n",
        "  def calculate_K(self,increment=[0,0,0,0]):\n",
        "    C,G,M,Y=np.add([self.C,self.G,self.M,self.Y],increment)\n",
        "    \n",
        "    return -C*gamma(-Y)*(M**Y+G**Y)\n",
        "\n",
        "  def reg_characteristic_function(self,u,t):\n",
        "    if u!=0:\n",
        "      return -(1-np.cos(u*self.D))/(1j*u)*self.characteristic_function(u,t)\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "  def L_error(self,L,B,b,beta,D,error):\n",
        "\n",
        "    Bounderror=D*B/(np.pi*beta*b**(1/beta))*gammaincc(1/beta,b*(L/2)**beta)-error\n",
        "\n",
        "    return L if Bounderror<0 else np.inf ##if bound is met, return L. Else, return infinity for penalty\n",
        "  def alpha_minimization(self, alpha):\n",
        "    t, error = self.t, self.error\n",
        "    return np.real((2 / alpha) * np.log(\n",
        "      (self.characteristic_function(1j * alpha, t) + self.characteristic_function(-1j * alpha, t)) / (2 * error / 3)))\n",
        "  def L_value(self,b):\n",
        "    res=optimize.minimize_scalar(self.L_error,args=(self.B,b,self.beta,self.D,self.error),bracket=[0, 1000], method='bounded',bounds=(0,35))\n",
        "    return res.x\n",
        "  def calculate_zeta(self, alpha):\n",
        "    C, G, M, Y = self.C, self.G, self.M, self.Y\n",
        "    term1 = -self.t * C * gamma(-Y) * (G ** Y - (G - alpha) ** Y)\n",
        "    term2 = -self.t * C * gamma(-Y) * (M ** Y - (M + alpha) ** Y)\n",
        "    term1 = np.clip(term1, a_min=None, a_max=600)#for numerical stability\n",
        "    term2 = np.clip(term2, a_min=None, a_max=600)#for numerical stability\n",
        "    return np.exp(np.logaddexp(term1, term2))\n",
        "\n",
        "  def calculate_h_from_C(self, C):\n",
        "    X = self.error * 2 * np.pi / (3 * C)\n",
        "    return -2 * np.pi * self.alpha / (np.log(X / (1 + X)))\n",
        "  def calculate_f(self,u,increment=[0,0,0,0]):\n",
        "    C,G,M,Y=np.add([self.C,self.G,self.M,self.Y],increment)\n",
        "    part1=(G**2/u**2+1)**(Y/2)*np.cos(Y*np.arctan(u/G))\n",
        "    part2=(M**2/u**2+1)**(Y/2)*np.cos(Y*np.arctan(u/M))\n",
        "    return gamma(-Y)*(part1+part2)\n",
        "  def abs_char(self,u,alpha):\n",
        "    return np.exp(self.t*self.K+self.t*self.C*np.abs(u)**self.Y*self.calculate_f(u,[0,-alpha,alpha,0]))\n",
        "\n",
        "\n",
        "  def calculate_bound_A_integrals(self, alpha, u_star):\n",
        "    \"\"\"\n",
        "    Calculates the bound A integrals for a given alpha and u_star.\n",
        "\n",
        "    Parameters:\n",
        "    alpha (float): The alpha value.\n",
        "    u_star (float): The u_star value.\n",
        "\n",
        "    Returns:\n",
        "    float: The calculated bound A value.\n",
        "    \"\"\"\n",
        "    stand_incr = [0, -alpha, alpha, 0]\n",
        "    ##for calculating positive alpha integrals and zeta\n",
        "    pos_alpha_K = self.calculate_K(increment=stand_incr)\n",
        "\n",
        "    pos_alpha_int = scipy.integrate.quad(lambda x: self.abs_char(x,alpha),10e-10,u_star)[0]\n",
        "\n",
        "    pos_alpha_upp = np.exp(self.t * pos_alpha_K) / (self.beta * self.b ** (1 / self.beta)) * gammaincc(1 / self.beta,\n",
        "                self.b * u_star ** self.beta)\n",
        "    \n",
        "    pos_alpha_all_int = self.calculate_zeta(alpha) * (pos_alpha_int + pos_alpha_upp)\n",
        "    ##for calculating negative alpha integrals and zeta\n",
        "    neg_incr = [0, alpha, -alpha, 0]\n",
        "    \n",
        "    neg_alpha_K = self.calculate_K(increment=neg_incr)\n",
        "\n",
        "    neg_alpha_int = scipy.integrate.quad(lambda x: self.abs_char(x,-alpha),10e-10,u_star)[0]\n",
        "    \n",
        "    neg_alpha_upp = np.exp(self.t * neg_alpha_K) / (self.beta * self.b ** (1 / self.beta)) * gammaincc(1 / self.beta,\n",
        "                   self.b * u_star ** self.beta)\n",
        "\n",
        "    neg_alpha_all_int = self.calculate_zeta(-alpha) * (neg_alpha_int + neg_alpha_upp)\n",
        "\n",
        "    \n",
        "    all_int = pos_alpha_all_int + neg_alpha_all_int+10e-9 #for numerical stability\n",
        "\n",
        "    #for numerical stability\n",
        "    part1 = np.exp(np.clip(((-self.D * self.alpha / 2+2*(self.D * self.alpha))), a_min=None, a_max=600))\n",
        "\n",
        "    part2 = 2 * np.exp(np.clip((-self.D * self.alpha / 2+ self.D * self.alpha), a_min=None, a_max=600))\n",
        "    part3 = np.exp(-self.D * self.alpha / 2)\n",
        "    \n",
        "    A = 1 / self.alpha * (part1+part2+part3) + all_int\n",
        "    return A \n",
        "\n",
        "  def generate_cdf(self):\n",
        "    \"\"\"\n",
        "    Generate the cumulative distribution function (CDF) for the Jump Diffusion Model.\n",
        "\n",
        "    Parameters:\n",
        "    \n",
        "\n",
        "    Returns:\n",
        "    - x_range (numpy.ndarray): An array of x values.\n",
        "    - M (numpy.ndarray): An array of real values representing the CDF.\n",
        "\n",
        "    \"\"\"\n",
        "    t=self.t\n",
        "    ##Regularization error\n",
        "    alpha_bounds = (0, np.min([self.G, self.M]))\n",
        "    optimization = optimize.minimize_scalar(self.alpha_minimization, 1, bounds=alpha_bounds)\n",
        "    self.alpha = optimization.x\n",
        "    print(\"Fourier Inversion Parameters:###########\")\n",
        "    print(\"alpha:\", self.alpha)\n",
        "    self.D = optimization.fun\n",
        "    print(\"D:\", self.D)\n",
        "    ##Truncating error\n",
        "    self.K = self.calculate_K()\n",
        "    K=self.K\n",
        "    self.beta = self.Y\n",
        "    self.B = np.exp(t * K)\n",
        "\n",
        "    if self.Y > 1:\n",
        "      u_star = max(self.G, self.M) * max(np.tan(np.pi / (2 * self.Y)), -1 / np.tan(self.Y * np.pi / 2))\n",
        "\n",
        "      self.b = -t * self.C * self.calculate_f(np.ceil(u_star))\n",
        "      C = self.calculate_bound_A_integrals(self.alpha, u_star)\n",
        "\n",
        "      h=self.calculate_h_from_C(C)\n",
        "      L_opt = max(self.L_value(self.b), np.ceil(u_star))\n",
        "     \n",
        "    elif self.Y > 0:\n",
        "      b = -t * 2 * self.C * gamma(-self.Y) * np.cos(np.pi * self.Y / 2)\n",
        "      L_opt = self.L_value(b)\n",
        "      A = (2 * np.exp(-self.D * self.alpha / 2) * (np.exp(self.D * self.alpha) + 1) ** 2 * self.B * gamma(\n",
        "        1 / self.beta)) / (self.alpha * self.beta * b ** (1 / self.beta))\n",
        "\n",
        "      h=self.calculate_h_from_C(A)\n",
        "    print(\"L_opt:\", L_opt)\n",
        "    print(\"h:\", h)\n",
        "\n",
        "    N = np.ceil(L_opt / h)\n",
        "    print(\"N:\", N)\n",
        "    eta = self.D / N\n",
        "    print(  \"eta:\", eta)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ###Vectorized Operations for faster computation\n",
        " \n",
        "    u_domain = np.arange(-N/2*h, (N/2)*h, h)\n",
        "    x_range = np.arange(-N/2*eta, (N/2)*eta, eta)\n",
        "\n",
        "    const = 1/(2*np.pi) * h\n",
        "\n",
        "    \n",
        "    reg_char_func_vect = np.vectorize(lambda u: self.reg_characteristic_function(u, t))\n",
        "\n",
        "    # Computing the characteristic values for each u in u_domain\n",
        "    characteristic_values = reg_char_func_vect(u_domain)\n",
        "\n",
        "    # Pre-compute the exponential part using broadcasting\n",
        "    # np.outer effectively creates a matrix where each row corresponds to an element in u_domain and each column to an element in x_range\n",
        "    exp_matrix = np.exp(-1j * np.outer(u_domain, x_range))\n",
        "\n",
        "    # Element-wise multiplication of exp_matrix with characteristic_values (reshaped for broadcasting)\n",
        "    vect = exp_matrix * characteristic_values[:, np.newaxis]\n",
        "\n",
        "    # Compute results by integrating (summing) over the u_domain for each x_range index\n",
        "    res = const * vect\n",
        "    real_res = np.sum(res, axis=0)  # Summing along the 'u_domain' axis\n",
        "\n",
        "    M2 = real_res  # M contains the real parts of the computed values for each x_range index\n",
        "    \n",
        "    M2+=np.ones(len(M2))*0.5\n",
        "    \n",
        "    return x_range,np.real(M2)\n",
        "\n",
        "# Test the code\n",
        "cgmy = CGMY(C=240 , G=5, M=5, Y=0.5, t=1/365, error=10e-7)\n",
        "\n",
        "C=cgmy.generate_cdf()\n",
        "sample_gen=random_number_gen.RandomNumberGen()\n",
        "sample_gen.inverse_transform(sample_gen.generate_matrix(100000,1),C[1],C[0])\n",
        "hist_values,bins,_=plt.hist(sample_gen.inverse_transform(sample_gen.generate_matrix(100000,1),C[1],C[0]),bins=100)\n",
        "Dx=C[0][1]-C[0][0]\n",
        "D=np.diff(C[1])/Dx\n",
        "\n",
        "plt.plot(C[0][1:],D*max(hist_values)/max(D))\n",
        "plt.show()\n",
        "\n",
        "plt.plot(C[0][1:],D)\n",
        "plt.plot(C[0],C[1])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA4t43H1bNKL",
        "outputId": "c970b0b4-36f8-49b4-ae4f-2f6758b2ac72"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "import random_number_gen\n",
        "gen=random_number_gen.RandomNumberGen()\n",
        "def black_scholes_call(S, K, T, r, sigma):\n",
        "    \"\"\"Calculate the Black-Scholes price of a European call option.\"\"\"\n",
        "    d1 = (np.log(S / K) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n",
        "    d2 = d1 - sigma * np.sqrt(T)\n",
        "    call_price = S * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)\n",
        "    return call_price\n",
        "\n",
        "def monte_carlo_call(S, K, T, r, sigma, paths):\n",
        "    \"\"\"Monte Carlo simulation for the European call option price.\"\"\"\n",
        "    dt = T\n",
        "    # Simulating the end stock price\n",
        "    ST = S * np.exp((r - 0.5 * sigma ** 2) * dt + sigma * np.sqrt(dt) * norm.ppf(np.array(gen.generate_matrix(paths,4,LHS=False)) ) )\n",
        "    # Calculating the payoff\n",
        "    payoffs = np.maximum(ST - K, 0)\n",
        "    # Discounting the payoff back to present value\n",
        "    call_price_mc = np.exp(-r * T) * np.mean(payoffs)\n",
        "    return call_price_mc\n",
        "def monte_carlo_call_antithetic(S, K, T, r, sigma, paths):\n",
        "    \"\"\"Monte Carlo simulation for the European call option price.\"\"\"\n",
        "    dt = T\n",
        "    # Simulating the end stock price\n",
        "    sample=norm.ppf(np.array(gen.generate_matrix(paths//2,4,LHS=True)) )\n",
        "    #np.random.standard_normal(paths//2)\n",
        "    sample=np.concatenate([sample,-sample])\n",
        "    ST = S * np.exp((r - 0.5 * sigma ** 2) * dt + sigma * np.sqrt(dt) * sample)\n",
        "    # Calculating the payoff\n",
        "    payoffs = np.maximum(ST - K, 0)\n",
        "    # Discounting the payoff back to present value\n",
        "    call_price_mc = np.exp(-r * T) * np.mean(payoffs)\n",
        "    \n",
        "    return call_price_mc\n",
        "\n",
        "def plot_convergence(S, K, T, r, sigma, max_paths, step,plot=False):\n",
        "    \"\"\"Plot the convergence of the Monte Carlo simulation to the Black-Scholes price.\"\"\"\n",
        "    bs_price = black_scholes_call(S, K, T, r, sigma)\n",
        "    paths_range = np.arange(step, max_paths + step, step)\n",
        "    mc_prices = []\n",
        "\n",
        "    for num_paths in paths_range:\n",
        "        mc_price = monte_carlo_call(S, K, T, r, sigma, num_paths)\n",
        "        mc_prices.append(mc_price)\n",
        "\n",
        "    diff=np.abs(mc_prices-bs_price*np.ones(len(mc_prices)))\n",
        "    if plot:\n",
        "        plt.plot(paths_range, diff, label='MC Estimate')\n",
        "    \n",
        "\n",
        "def plot_convergence_antithetic(S, K, T, r, sigma, max_paths, step,plot=False):\n",
        "    \"\"\"Plot the convergence of the Monte Carlo simulation to the Black-Scholes price.\"\"\"\n",
        "    bs_price = black_scholes_call(S, K, T, r, sigma)\n",
        "    paths_range = np.arange(step, max_paths + step, step)\n",
        "    mc_prices = []\n",
        "\n",
        "    for num_paths in paths_range:\n",
        "        mc_price = monte_carlo_call_antithetic(S, K, T, r, sigma, num_paths)\n",
        "        mc_prices.append(mc_price)\n",
        "\n",
        "    diff=np.abs(mc_prices-bs_price*np.ones(len(mc_prices)))\n",
        "    if plot:\n",
        "        plt.plot(paths_range, diff, label='MC Estimate with Variance Reduction')\n",
        "    # plt.plot(paths_range, diff, label='MC Estimate Antithetic')\n",
        "\n",
        "        plt.xlabel('Number of Paths')\n",
        "        plt.ylabel('absolute difference')\n",
        "        plt.title('Convergence of Monte Carlo Estimates to Black-Scholes Price')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "# Example parameters\n",
        "S = 100  # Stock price\n",
        "K = 100  # Strike price\n",
        "T = 1    # Time to expiration in years\n",
        "r = 0.05 # Risk-free rate\n",
        "sigma = 0.2  # Volatility\n",
        "\n",
        "# Uncomment below line to execute the plotting function\n",
        "# %timeit plot_convergence(S, K, T, r, sigma, 100000, 100)\n",
        "# %timeit plot_convergence_antithetic(S, K, T, r, sigma, 100000, 100)\n",
        "plot_convergence(S, K, T, r, sigma, 1000, 10,plot=True)\n",
        "plot_convergence_antithetic(S, K, T, r, sigma, 1000, 10,plot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "####Model implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "import scipy\n",
        "import math\n",
        "import random_number_gen\n",
        "import scipy.optimize as optimize\n",
        "gen=random_number_gen.RandomNumberGen()\n",
        "from scipy.special import gamma,gammaincc,gammainc,gammaincinv,gammainccinv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Merton():\n",
        "    def __init__(self,mu,sigma,lambda_,muJ,sigmaJ):\n",
        "        self.mu=mu\n",
        "        self.sigma=sigma\n",
        "        self.lambda_=lambda_\n",
        "        self.muJ=muJ\n",
        "        self.sigma_J=sigmaJ\n",
        "    def simulate_end(self,paths,T,S0=100):\n",
        "        S=S0*np.exp((self.mu-self.sigma**2/2)*T )\n",
        "        poisson_sample=gen.generate_poisson(paths,1,self.lambda_*T)\n",
        "        normal_sample=gen.generate_normal(paths,1)\n",
        "        max_poisson=np.max(poisson_sample)\n",
        "        jump_sample=gen.generate_normal(paths,max_poisson,self.muJ,self.sigma_J)\n",
        "        #%timeit np.array([np.concatenate([np.ones(int(x)),np.zeros(int(max_poisson-x))]) for x in poisson_sample])\n",
        "        out=np.array([np.concatenate([np.ones(int(x)),np.zeros(int(max_poisson-x))]) for x in poisson_sample])\n",
        "        #%timeit np.sum(np.where(out==1,jump_sample,np.zeros((n,int(max_poisson)))),axis=1) ##matrix of 1s and 0s where the sum of each row is equal to the poisson var\n",
        "        jump_vect=np.sum(np.where(out==1,jump_sample,np.zeros((paths,int(max_poisson)))),axis=1)[:,np.newaxis]\n",
        "        #print((self.sigma*math.sqrt(T)*normal_sample).shape)\n",
        "        S=S*np.exp(self.sigma*math.sqrt(T)*normal_sample)*np.exp(jump_vect)\n",
        "        #print(jump_vect.shape)\n",
        "        #print(S.shape)\n",
        "        return S\n",
        "    def simulate_paths(self,paths,T,N,S0=100):\n",
        "        dt=T/N\n",
        "        S=S0*np.ones((paths,N))\n",
        "        const=np.exp((self.mu-self.sigma**2/2)*dt )\n",
        "        poisson_sample=gen.generate_poisson(paths,N,self.lambda_*dt)\n",
        "        normal_sample=gen.generate_normal(paths,N)\n",
        "        \n",
        "        for l in range(1,N):\n",
        "            max_poisson=np.max(poisson_sample[:,l])\n",
        "            jump_sample=gen.generate_normal(paths,max_poisson,self.muJ,self.sigma_J)\n",
        "            out=np.array([np.concatenate([np.ones(int(x)),np.zeros(int(max_poisson-x))]) for x in poisson_sample[:,l]])\n",
        "            \n",
        "            S[:,l]=S[:,l-1]*const*np.exp(self.sigma*math.sqrt(T)*normal_sample[:,l])*np.exp(np.sum(np.where(out==1,jump_sample,np.zeros((paths,int(max_poisson)))),axis=1))\n",
        "        \n",
        "        return S\n",
        "    def update_params(self,params):\n",
        "        self.mu,self.sigma,self.lambda_,self.muJ,self.sigma_J=params\n",
        "    def update_time(self,T):\n",
        "        pass\n",
        "    def prior(self,params):\n",
        "        mu,sigma,lambda_,muJ,sigmaJ=params\n",
        "        if sigma<0 or lambda_<0 or sigmaJ<0:\n",
        "            return 10e-9\n",
        "        prob_mu=norm.pdf(mu,0,0.1)\n",
        "        prob_sigma=norm.pdf(sigma,0,0.1)\n",
        "        prob_lambda_=norm.pdf(lambda_,0,0.1)\n",
        "        prob_muJ=norm.pdf(muJ,0,0.1)\n",
        "        prob_sigmaJ=norm.pdf(sigmaJ,0,0.1)\n",
        "        return prob_mu*prob_sigma*prob_lambda_*prob_muJ*prob_sigmaJ\n",
        "\n",
        "X=Merton(0.05,0.1,0.01,-0.05,0.1)\n",
        "S=X.simulate_end(100,20)\n",
        "print(S)\n",
        "plt.plot(S.transpose())\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Kou():\n",
        "    def __init__(self,mu,sigma,lambda_,p,eta1,eta2):\n",
        "        self.mu=mu\n",
        "        self.sigma=sigma\n",
        "        self.lambda_=lambda_\n",
        "        self.p=p\n",
        "        self.eta1=eta1\n",
        "        self.eta2=eta2\n",
        "    def simulate_end(self,paths,T,S0=100):\n",
        "        S=S0*np.exp((self.mu-self.sigma**2/2)*T )\n",
        "        poisson_sample=gen.generate_poisson(paths,1,self.lambda_*T)\n",
        "        normal_sample=gen.generate_normal(paths,1)\n",
        "        max_poisson=np.max(poisson_sample)\n",
        "        jump_sample=gen.generate_double_exponential(paths,max_poisson,self.p,self.eta1,self.eta2)\n",
        "        out=np.array([np.concatenate([np.ones(int(x)),np.zeros(int(max_poisson-x))]) for x in poisson_sample])\n",
        "        jump_vect=np.sum(np.where(out==1,jump_sample,np.zeros((paths,int(max_poisson)))),axis=1)[:,np.newaxis]\n",
        "        S=S*np.exp(self.sigma*math.sqrt(T)*normal_sample)*np.exp(jump_vect)\n",
        "        return S\n",
        "    def update_time(self,t):\n",
        "        pass\n",
        "    def update_params(self,params):\n",
        "        self.mu,self.sigma,self.lambda_,self.p,self.eta1,self.eta2=params\n",
        "    \n",
        "    def simulate_paths(self,paths,T,N,S0=100):\n",
        "        dt=T/N\n",
        "        S=S0*np.ones((paths,N))\n",
        "        const=np.exp((self.mu-self.sigma**2/2)*dt )\n",
        "        poisson_sample=gen.generate_poisson(paths,N,self.lambda_*dt)\n",
        "        normal_sample=gen.generate_normal(paths,N)\n",
        "        \n",
        "        for l in np.arange(1,int(N)):\n",
        "            max_poisson=np.max(poisson_sample[:,l])\n",
        "            jump_sample=gen.generate_double_exponential(paths,max_poisson,self.p,self.eta1,self.eta2)\n",
        "            out=np.array([np.concatenate([np.ones(int(x)),np.zeros(int(max_poisson-x))]) for x in poisson_sample[:,l]])\n",
        "            \n",
        "            S[:,l]=S[:,l-1]*np.exp(self.sigma*math.sqrt(T)*normal_sample[:,l])*np.exp(np.sum(np.where(out==1,jump_sample,np.zeros((paths,int(max_poisson)))),axis=1))\n",
        "        \n",
        "        return S\n",
        "    def update_params(self,params):\n",
        "        self.mu,self.sigma,self.lambda_,self.p,self.eta1,self.eta2=params\n",
        "    def prior(self,params):##for Parameter Estimation later\n",
        "        mu,sigma,lambda_,p,eta1,eta2=params\n",
        "        if sigma<0 or lambda_<0 or p<0 or p>1 or eta1<0 or eta2<0:\n",
        "            return 10e-9\n",
        "        mu_prob=norm.pdf(mu,0,0.1)\n",
        "        sigma_prob=norm.pdf(sigma,0.3,0.1)\n",
        "        lambda_prob=norm.pdf(lambda_,0.005,0.001)\n",
        "        p_prob=norm.pdf(p,0.5,0.)\n",
        "        eta1_prob=norm.pdf(eta1,0.1,0.1)\n",
        "        eta2_prob=norm.pdf(eta2,0.1,0.1)\n",
        "\n",
        "                             \n",
        "        return mu_prob*sigma_prob*lambda_prob*p_prob*eta1_prob*eta2_prob\n",
        "\n",
        "\n",
        "X=Kou(0.05,0.1,0.01,0.5,0.1,0.1)\n",
        "S=X.simulate_paths(100,1,20)\n",
        "plt.plot(S.transpose())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CGMY():\n",
        "  def __init__(self,C,G,M,Y,eta,mu):\n",
        "      self.C=C\n",
        "      self.G=G\n",
        "      self.M=M\n",
        "      if np.abs(Y-int(Y))<0.05:\n",
        "        Y-=0.05\n",
        "      self.Y=Y\n",
        "      self.eta=eta\n",
        "      self.generated=False\n",
        "      self.mu=mu\n",
        "  \n",
        "  def characteristic_function(self,u,t,increment=[0,0,0,0]):\n",
        "\n",
        "    C,G,M,Y=np.add([self.C,self.G,self.M,self.Y],increment)\n",
        "    return np.exp(t*C*gamma(-Y)*((M-1j*u)**Y-M**Y+(G+1j*u)**Y-G**Y))\n",
        "\n",
        "  def calculate_K(self,increment=[0,0,0,0]):\n",
        "    C,G,M,Y=np.add([self.C,self.G,self.M,self.Y],increment)\n",
        "    \n",
        "    return -C*gamma(-Y)*(M**Y+G**Y)\n",
        "\n",
        "  def reg_characteristic_function(self,u,t):\n",
        "    if u!=0:\n",
        "      return -(1-np.cos(u*self.D))/(1j*u)*self.characteristic_function(u,t)\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "  def L_error(self,L,B,b,beta,D,error):\n",
        "\n",
        "    Bounderror=D*B/(np.pi*beta*b**(1/beta))*gammaincc(1/beta,b*(L/2)**beta)-error\n",
        "\n",
        "    return L if Bounderror<0 else np.inf ##if bound is met, return L. Else, return infinity for penalty\n",
        "  def alpha_minimization(self, alpha):\n",
        "    t, error = self.t, self.error\n",
        "    return np.real((2 / alpha) * np.log(\n",
        "      (self.characteristic_function(1j * alpha, t) + self.characteristic_function(-1j * alpha, t)) / (2 * error / 3)))\n",
        "  def L_value(self,b):\n",
        "    res=optimize.minimize_scalar(self.L_error,args=(self.B,b,self.beta,self.D,self.error),bracket=[0, 1000], method='bounded',bounds=(0,35))\n",
        "    return res.x\n",
        "  def calculate_zeta(self, alpha):\n",
        "    C, G, M, Y = self.C, self.G, self.M, self.Y\n",
        "    term1 = -self.t * C * gamma(-Y) * (G ** Y - (G - alpha) ** Y)\n",
        "    term2 = -self.t * C * gamma(-Y) * (M ** Y - (M + alpha) ** Y)\n",
        "    term1 = np.clip(term1, a_min=None, a_max=600)#for numerical stability\n",
        "    term2 = np.clip(term2, a_min=None, a_max=600)#for numerical stability\n",
        "    return np.exp(np.logaddexp(term1, term2))\n",
        "\n",
        "  def calculate_h_from_C(self, C):\n",
        "    X = self.error * 2 * np.pi / (3 * C)\n",
        "    return -2 * np.pi * self.alpha / (np.log(X / (1 + X)))\n",
        "  def calculate_f(self,u,increment=[0,0,0,0]):\n",
        "    C,G,M,Y=np.add([self.C,self.G,self.M,self.Y],increment)\n",
        "    part1=(G**2/u**2+1)**(Y/2)*np.cos(Y*np.arctan(u/G))\n",
        "    part2=(M**2/u**2+1)**(Y/2)*np.cos(Y*np.arctan(u/M))\n",
        "    return gamma(-Y)*(part1+part2)\n",
        "  def abs_char(self,u,alpha):\n",
        "    return np.exp(self.t*self.K+self.t*self.C*np.abs(u)**self.Y*self.calculate_f(u,[0,-alpha,alpha,0]))\n",
        "\n",
        "\n",
        "  def calculate_bound_A_integrals(self, alpha, u_star):\n",
        "    \"\"\"\n",
        "    Calculates the bound A integrals for a given alpha and u_star.\n",
        "\n",
        "    Parameters:\n",
        "    alpha (float): The alpha value.\n",
        "    u_star (float): The u_star value.\n",
        "\n",
        "    Returns:\n",
        "    float: The calculated bound A value.\n",
        "    \"\"\"\n",
        "    stand_incr = [0, -alpha, alpha, 0]\n",
        "    ##for calculating positive alpha integrals and zeta\n",
        "    pos_alpha_K = self.calculate_K(increment=stand_incr)\n",
        "\n",
        "    pos_alpha_int = scipy.integrate.quad(lambda x: self.abs_char(x,alpha),10e-10,u_star)[0]\n",
        "\n",
        "    pos_alpha_upp = np.exp(self.t * pos_alpha_K) / (self.beta * self.b ** (1 / self.beta)) * gammaincc(1 / self.beta,\n",
        "                self.b * u_star ** self.beta)\n",
        "    \n",
        "    pos_alpha_all_int = self.calculate_zeta(alpha) * (pos_alpha_int + pos_alpha_upp)\n",
        "    ##for calculating negative alpha integrals and zeta\n",
        "    neg_incr = [0, alpha, -alpha, 0]\n",
        "    \n",
        "    neg_alpha_K = self.calculate_K(increment=neg_incr)\n",
        "\n",
        "    neg_alpha_int = scipy.integrate.quad(lambda x: self.abs_char(x,-alpha),10e-10,u_star)[0]\n",
        "    \n",
        "    neg_alpha_upp = np.exp(self.t * neg_alpha_K) / (self.beta * self.b ** (1 / self.beta)) * gammaincc(1 / self.beta,\n",
        "                   self.b * u_star ** self.beta)\n",
        "\n",
        "    neg_alpha_all_int = self.calculate_zeta(-alpha) * (neg_alpha_int + neg_alpha_upp)\n",
        "\n",
        "    \n",
        "    all_int = pos_alpha_all_int + neg_alpha_all_int+10e-9 #for numerical stability\n",
        "\n",
        "    #for numerical stability\n",
        "    part1 = np.exp(np.clip(((-self.D * self.alpha / 2+2*(self.D * self.alpha))), a_min=None, a_max=600))\n",
        "\n",
        "    part2 = 2 * np.exp(np.clip((-self.D * self.alpha / 2+ self.D * self.alpha), a_min=None, a_max=600))\n",
        "    part3 = np.exp(-self.D * self.alpha / 2)\n",
        "    \n",
        "    A = 1 / self.alpha * (part1+part2+part3) + all_int\n",
        "    return A \n",
        "\n",
        "  def generate_cdf(self):\n",
        "    \"\"\"\n",
        "    Generate the cumulative distribution function (CDF) for the Jump Diffusion Model.\n",
        "\n",
        "    Parameters:\n",
        "    \n",
        "\n",
        "    Returns:\n",
        "    - x_range (numpy.ndarray): An array of x values.\n",
        "    - M (numpy.ndarray): An array of real values representing the CDF.\n",
        "\n",
        "    \"\"\"\n",
        "    t=self.t\n",
        "    ##Regularization error\n",
        "    alpha_bounds = (0, np.min([self.G, self.M]))\n",
        "    optimization = optimize.minimize_scalar(self.alpha_minimization, 1, bounds=alpha_bounds)\n",
        "    self.alpha = optimization.x\n",
        "    #print(\"Fourier Inversion Parameters:###########\")\n",
        "    #print(\"alpha:\", self.alpha)\n",
        "    self.D = optimization.fun\n",
        "    #print(\"D:\", self.D)\n",
        "    ##Truncating error\n",
        "    self.K = self.calculate_K()\n",
        "    K=self.K\n",
        "    self.beta = self.Y\n",
        "    self.B = np.exp(t * K)\n",
        "\n",
        "    if self.Y > 1:\n",
        "      u_star = max(self.G, self.M) * max(np.tan(np.pi / (2 * self.Y)), -1 / np.tan(self.Y * np.pi / 2))\n",
        "\n",
        "      self.b = -t * self.C * self.calculate_f(np.ceil(u_star))\n",
        "      C = self.calculate_bound_A_integrals(self.alpha, u_star)\n",
        "\n",
        "      h=self.calculate_h_from_C(C)\n",
        "      L_opt = max(self.L_value(self.b), np.ceil(u_star))\n",
        "     \n",
        "    elif self.Y > 0:\n",
        "      b = -t * 2 * self.C * gamma(-self.Y) * np.cos(np.pi * self.Y / 2)\n",
        "      L_opt = self.L_value(b)\n",
        "      A = (2 * np.exp(-self.D * self.alpha / 2) * (np.exp(self.D * self.alpha) + 1) ** 2 * self.B * gamma(\n",
        "        1 / self.beta)) / (self.alpha * self.beta * b ** (1 / self.beta))\n",
        "\n",
        "      h=self.calculate_h_from_C(A)\n",
        "    #print(\"L_opt:\", L_opt)\n",
        "    #print(\"h:\", h)\n",
        "\n",
        "    N = np.ceil(L_opt / h)\n",
        "    #print(\"N:\", N)\n",
        "    eta = self.D / N\n",
        "    #print(  \"eta:\", eta)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ###Vectorized Operations for faster computation\n",
        " \n",
        "    u_domain = np.arange(-N/2*h, (N/2)*h, h)\n",
        "    x_range = np.arange(-N/2*eta, (N/2)*eta, eta)\n",
        "\n",
        "    const = 1/(2*np.pi) * h\n",
        "\n",
        "    \n",
        "    reg_char_func_vect = np.vectorize(lambda u: self.reg_characteristic_function(u, t))\n",
        "\n",
        "    # Computing the characteristic values for each u in u_domain\n",
        "    characteristic_values = reg_char_func_vect(u_domain)\n",
        "\n",
        "    # Pre-compute the exponential part using broadcasting\n",
        "    # np.outer effectively creates a matrix where each row corresponds to an element in u_domain and each column to an element in x_range\n",
        "    exp_matrix = np.exp(-1j * np.outer(u_domain, x_range))\n",
        "\n",
        "    # Element-wise multiplication of exp_matrix with characteristic_values (reshaped for broadcasting)\n",
        "    vect = exp_matrix * characteristic_values[:, np.newaxis]\n",
        "\n",
        "    # Compute results by integrating (summing) over the u_domain for each x_range index\n",
        "    res = const * vect\n",
        "    real_res = np.sum(res, axis=0)  # Summing along the 'u_domain' axis\n",
        "\n",
        "    M2 = real_res  # M contains the real parts of the computed values for each x_range index\n",
        "    \n",
        "    M2+=np.ones(len(M2))*0.5\n",
        "    self.generated=True\n",
        "    self.CumDensity=(x_range,np.real(M2))\n",
        "    return x_range,np.real(M2)\n",
        "  \n",
        "    \n",
        "  def generate_inverse_transform_sample(self,n,rows):\n",
        "    if not self.generated:\n",
        "      self.generate_cdf()\n",
        "    return gen.inverse_transform(gen.generate_matrix(n,rows),self.CumDensity[1],self.CumDensity[0])\n",
        "  def generate_sample(self,n,rows,t,error):\n",
        "    self.t=t\n",
        "    self.error=error\n",
        "    if self.Y>0:\n",
        "      out=self.generate_inverse_transform_sample(n,rows)\n",
        "    else:\n",
        "      out=gen.generate_CGMY_Ylessthan1(n,rows,self.C,self.G,self.M,self.Y)\n",
        "    return out\n",
        "  def update_params(self,params):\n",
        "    self.C,self.G,self.M,self.Y,self.eta=params\n",
        "    self.generated=False\n",
        "  def update_time(self,t):\n",
        "    self.t=t\n",
        "    self.generated=False\n",
        "  def calculate_omega(self):\n",
        "    omega=-np.log(self.characteristic_function(-1j,self.t))/self.t\n",
        "    return omega\n",
        "  def simulate_end(self,paths,T,s0,error=10e-15):\n",
        "    S=s0\n",
        "    cgmy_sample=np.real(self.generate_sample(paths,1,T,error))\n",
        "    omega=self.calculate_omega()\n",
        "   \n",
        "    S=np.exp((self.mu+omega-self.eta**2/2))*S\n",
        "    normal_sample=gen.generate_normal(paths,1)\n",
        " \n",
        "    S=S*np.exp(np.sqrt(T)*cgmy_sample)\n",
        "   \n",
        "    S=S*np.exp(self.eta*np.sqrt(T)*normal_sample)\n",
        "    \n",
        "    return np.real(S)\n",
        "  def simulate_paths(self,paths,N,T,s0,error):\n",
        "    dt=T/N\n",
        "    S=s0*np.ones((paths,N))\n",
        "    cgmy_sample=self.generate_sample(paths,N,dt,error)\n",
        "    omega=self.calculate_omega()\n",
        "    S=np.exp((self.mu+omega-self.eta**2/2))*S\n",
        "    normal_sample=gen.generate_normal(paths,N)\n",
        "    for l in range(1,N):\n",
        "        S[:,l]=S[:,l-1]*np.exp(cgmy_sample[:,l]+self.eta*np.sqrt(dt)*normal_sample[:,l])\n",
        "    return np.real(S)\n",
        "\n",
        "  \n",
        "X=CGMY(2,12,12,-0.6,0.04,0.05)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###Downloading the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "import datetime\n",
        "from scipy.special import gamma,gammaincc,gammainc,gammaincinv,gammainccinv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "__TICKERS_TO_CHECK=[\"TSLA\",\"AAPL\",\"MSFT\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Download_data():\n",
        "    def __init__(self,tickers):\n",
        "        self.tickers=tickers\n",
        "        self.columns_to_keep=[\"contractSymbol\",\t\"strike\",\"volume\",\t\"lastPrice\",\t\"impliedVolatility\",\t\"currency\"]\n",
        "    def download_data(self,ticker,period):\n",
        "        data=yf.download(ticker,period=period)\n",
        "        data.log_price=np.diff(np.log(data[\"Adj Close\"]))\n",
        "        pd.DataFrame(data.log_price).to_csv(f\"{ticker}.csv\")\n",
        "        return {datetime.datetime.today().strftime('%Y-%m-%d'):ticker}\n",
        "    def get_option_chain(self,ticker,nb_strikes,nb_exp):\n",
        "        YFTICKER=yf.Ticker(ticker)\n",
        "        option_chain=YFTICKER.option_chain()\n",
        "        current_price=YFTICKER.history(period=\"1d\")[\"Close\"][0]\n",
        "       \n",
        "        \n",
        "        exp=list(YFTICKER._expirations.keys())[0:nb_exp]\n",
        "        \n",
        "        output=pd.DataFrame()\n",
        "        for l in exp:\n",
        "            \n",
        "            temp_option_chain=YFTICKER.option_chain(l)\n",
        "            all_options=temp_option_chain.calls._append(temp_option_chain.puts)\n",
        "            delta=np.sort(np.abs(np.diff(all_options[\"strike\"])))[0]\n",
        "            \n",
        "            all_options=all_options[all_options[\"strike\"].between(current_price-delta*nb_strikes,current_price+delta*nb_strikes)]\n",
        "            all_options=all_options[self.columns_to_keep]\n",
        "            output=pd.concat([output,all_options],ignore_index=True)\n",
        "        output.to_csv(f\"{ticker}_option_chain.csv\")\n",
        "        return {datetime.datetime.today().strftime('%Y-%m-%d'):ticker}\n",
        "    def get_data(self):\n",
        "        output={}\n",
        "        for l in self.tickers:\n",
        "            try:\n",
        "                pd.read_csv(f\"{l}.csv\")\n",
        "                import os\n",
        "                import datetime\n",
        "\n",
        "                \n",
        "\n",
        "                # Get the modification time of the file\n",
        "                file_time = os.path.getmtime(f\"{l}.csv\")\n",
        "\n",
        "                # Convert the modification time to a datetime object\n",
        "                file_date = datetime.datetime.fromtimestamp(file_time).date()\n",
        "\n",
        "                # Get today's date\n",
        "                today = datetime.date.today()\n",
        "\n",
        "                # Compare the file date with today's date\n",
        "                if file_date == today:\n",
        "                    print(\"The time from the asset return file matches today's date.\")\n",
        "                else:\n",
        "                    print(\"The time from the asset return file does not match today's date.\")\n",
        "                    output.update(self.download_data(l,\"1y\"))\n",
        "            except:\n",
        "                output.update(self.download_data(l,\"1y\"))\n",
        "            try:\n",
        "                pd.read_csv(f\"{l}_option_chain.csv\")\n",
        "                import os\n",
        "                import datetime\n",
        "\n",
        "                \n",
        "\n",
        "                # Get the modification time of the file\n",
        "                file_time = os.path.getmtime(f\"{l}_option_chain.csv\")\n",
        "\n",
        "                # Convert the modification time to a datetime object\n",
        "                file_date = datetime.datetime.fromtimestamp(file_time).date()\n",
        "\n",
        "                # Get today's date\n",
        "                today = datetime.date.today()\n",
        "\n",
        "                # Compare the file date with today's date\n",
        "                if file_date == today:\n",
        "                    print(\"The time from the option chain file matches today's date.\")\n",
        "                else:\n",
        "                    print(\"The time from the option chain file does not match today's date.\")\n",
        "                    output.update(self.get_option_chain(l,5,5))\n",
        "            except:\n",
        "                output.update(self.get_option_chain(l,5,5))\n",
        "        \n",
        "        return output\n",
        "\n",
        "x=Download_data(__TICKERS_TO_CHECK)\n",
        "x.get_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###Calculating Option Prices:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Option_Price_Calculator():\n",
        "    def __init__(self):\n",
        "        self.discount_rate=0.05\n",
        "        pass\n",
        "    def transform_into_df(self,option_names):\n",
        "        ext=option_names.str.extract(r'(\\D{4})(\\d{6})(\\D)(\\d+)', expand=True)\n",
        "        ext.columns=[\"Ticker\",\"Date\",\"Type\",\"Strike\"]\n",
        "        \n",
        "        \n",
        "        ext.Date=pd.to_datetime(ext.Date,format=\"%y%m%d\")\n",
        "        ext.Strike=ext.Strike.astype(float)/1000\n",
        "        out=pd.concat([option_names,ext],axis=1)\n",
        "        out.columns=[\"Option\",\"Ticker\",\"Date\",\"Type\",\"Strike\"]\n",
        "        return out\n",
        "    def price_options(self,option_chain,s0,nb_simulations,model):\n",
        "        X=self.transform_into_df(option_chain[\"contractSymbol\"])\n",
        "        all_sims=pd.DataFrame()\n",
        "        \n",
        "        X[\"Sim_price\"]=np.nan\n",
        "        for l in X.Date.unique():\n",
        "            \n",
        "            time_to_exp=((l-pd.Timestamp.today()).days+1)/365\n",
        "            model.update_time(time_to_exp)\n",
        "            \n",
        "            sim=np.real(model.simulate_end(nb_simulations,time_to_exp,s0))\n",
        "            \n",
        "            sim=pd.DataFrame(sim,columns=[datetime.datetime.strftime(l,\"%Y-%m-%d\")])\n",
        "            all_sims=pd.concat([all_sims,pd.DataFrame(sim)],axis=1)\n",
        "        \n",
        "        for i,j in enumerate(X.Date):\n",
        "            Delay=(j-pd.Timestamp.today()).days/365\n",
        "            index=datetime.datetime.strftime(j,\"%Y-%m-%d\")\n",
        "            \n",
        "            exp_S=s0*np.exp(Delay*self.discount_rate)\n",
        "            \n",
        "            sim_prices=all_sims[index]\n",
        "            if X.Type[i]==\"C\":\n",
        "                Exp_price=np.maximum(sim_prices-X.Strike[i],0)\n",
        "                \n",
        "            else:\n",
        "                Exp_price=np.maximum(X.Strike[i]-sim_prices,0)\n",
        "            \n",
        "            \n",
        "\n",
        "            b_hat=np.cov(sim_prices,Exp_price)[0,1]/np.var(sim_prices)\n",
        "            \n",
        "            \n",
        "            Control_Var_adj=Exp_price-b_hat*(all_sims[index]-exp_S)\n",
        "            \n",
        "            X.loc[i,\"Sim_price\"]=max(np.exp(-Delay*self.discount_rate)*np.mean(Control_Var_adj),0)\n",
        "        return X\n",
        "p=Option_Price_Calculator()\n",
        "Price=p.price_options(pd.read_csv(\"AAPL_option_chain.csv\"),180,1000,CGMY(5,12,12,-0.6,0.04,0.05))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import gaussian_kde\n",
        "import scipy.stats as stats\n",
        "\n",
        "\n",
        "class RandomWalkMetropolisHastings:\n",
        "    def __init__(self, initial_state, proposal_params, data, model,limits,special=0):\n",
        "        self.state = initial_state\n",
        "        self.proposal_params = proposal_params\n",
        "        self.data = data[\"0\"]\n",
        "        self.model = model\n",
        "        self.accepted = 0\n",
        "        self.rejected = 0\n",
        "        self.likelihoods = []\n",
        "        self.log_like=-np.inf\n",
        "        self.min=limits[:,0]\n",
        "        self.max=limits[:,1]\n",
        "        self.special=special\n",
        "        self.lambda_=0.1\n",
        "        self.max_likelihood=-np.inf\n",
        "        self.max_state=initial_state\n",
        "        # Better way to set an initial log-likelihood value\n",
        "         # Use default_rng for better randomness\n",
        "\n",
        "    def step(self):\n",
        "        \n",
        "        proposed_state = self.proposal_distribution(self.state, self.proposal_params)\n",
        "        if not( np.all((proposed_state >= self.min) & (proposed_state <= self.max))):\n",
        "            return self.state\n",
        "        try:\n",
        "            new_ll = self.log_likelihood(proposed_state)#+np.log(self.model.prior(proposed_state))\n",
        "        except RuntimeWarning as e:\n",
        "            new_ll = -50\n",
        "        except RuntimeError as e:\n",
        "            new_ll = -50\n",
        "        \n",
        "        current_ll = self.log_like#+np.log(self.model.prior(self.state))\n",
        "        if new_ll>self.max_likelihood:\n",
        "            self.max_likelihood=new_ll\n",
        "            self.max_state=proposed_state\n",
        "        log_alpha = new_ll - current_ll\n",
        "\n",
        "        if np.log(gen.Scrambled_Random()) < log_alpha:\n",
        "            self.state = proposed_state\n",
        "            self.accepted += 1\n",
        "            self.log_like = new_ll \n",
        "            self.likelihoods.append(new_ll)\n",
        "        else:\n",
        "            self.rejected += 1\n",
        "            self.likelihoods.append(current_ll)  \n",
        "\n",
        "        return self.state\n",
        "    def reset_acceptance(self):\n",
        "        self.accepted=0\n",
        "        self.rejected=0\n",
        "        \n",
        "    def run(self, n):\n",
        "        stop=False\n",
        "        k=0\n",
        "        while True:\n",
        "            k+=1\n",
        "            self.step()\n",
        "            if k % 100 == 0:\n",
        "                #print(f\"Step {k}, Acceptance Rate: {self.acceptance_rate():.2f}\")\n",
        "                if self.acceptance_rate()>0.9:\n",
        "                    stop=True\n",
        "                    break\n",
        "\n",
        "                \n",
        "                if self.acceptance_rate()<0.01: ## early stopping if not enough new samples are discovered\n",
        "                    break\n",
        "                self.reset_acceptance()\n",
        "        if stop:#early stopping\n",
        "            return        0,0 \n",
        "        self.state=self.max_state\n",
        "        self.log_like=self.max_likelihood\n",
        "        sim = self.simulate_pdf(1000)\n",
        "        x, y, _ = plt.hist(self.data, bins=100,  label='Data Histogram')\n",
        "        if self.likelihoods==[]:\n",
        "            return 0,0\n",
        "        plt.plot(sim[0], sim[1]*x[len(x)//2]/max(sim[1]), label='Simulated PDF')\n",
        "        plt.legend()\n",
        "        plt.xlim(min(y) - 0.05, max(y) + 0.05)\n",
        "        plt.show()\n",
        "\n",
        "        plt.plot(self.likelihoods)\n",
        "        plt.title(\"Log-Likelihood over Iterations\")\n",
        "        plt.xlabel(\"Iteration\")\n",
        "        plt.ylabel(\"Log-Likelihood\")\n",
        "        plt.show()\n",
        "        print(self.likelihoods[-1])\n",
        "        print(self.state)\n",
        "        return self.likelihoods[-1],self.state\n",
        "\n",
        "    def acceptance_rate(self):\n",
        "        return self.accepted / (self.accepted + self.rejected+10e-9)\n",
        "\n",
        "    def simulate_pdf(self, n):\n",
        "        sims = np.array(self.model.simulate_end(n, 1/365, 1))  # Adjust according to your model's simulate_end method\n",
        "        sims = sims.reshape(len(sims))\n",
        "        log_returns = np.diff(np.log(sims))\n",
        "        kde = gaussian_kde(log_returns)\n",
        "        if self.special==1:\n",
        "            try:\n",
        "                x=self.model.generate_cdf()[0]\n",
        "            except UnboundLocalError as e:\n",
        "                \n",
        "                return 0\n",
        "            \n",
        "        else:\n",
        "\n",
        "            x = np.linspace(min(self.data) - 0.05, max(self.data) + 0.05, 400)\n",
        "        pdf = kde(x)\n",
        "        \n",
        "        #pdf=pdf/np.1sum(pdf)\n",
        "          ### in case of overshooting the pdf in bounds by too much, penalize the entire pdf so this parameter setting is not chosen\n",
        "        return x, pdf\n",
        "\n",
        "    def log_likelihood(self, state):\n",
        "       \n",
        "        \n",
        "            \n",
        "        self.model.update_params(state)\n",
        "        saved = self.simulate_pdf(500)\n",
        "        if saved==0:\n",
        "            return -500\n",
        "        likelihood = np.sum(np.log(np.interp(self.data, saved[0], saved[1], left=1e-10, right=1e-10)))  # Avoid log(0)\n",
        "        return likelihood-self.lambda_*np.std(saved[1])\n",
        "\n",
        "    def proposal_distribution(self, state, params):\n",
        "        selected = np.random.choice(len(state))\n",
        "        #print(selected)\n",
        "        #print([[0]*selected,[np.random.normal(0, params)[selected]],[0]*(len(params)-selected-1)])\n",
        "        return state + np.concatenate([[0]*selected,[np.random.normal(0, params)[selected]],[0]*(len(params)-selected-1)])\n",
        "\n",
        "# Example usage:\n",
        "Price = pd.read_csv(\"AAPL.csv\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "Merton_limits=np.array([(0,np.inf),(0,np.inf),(0,np.inf),(-np.inf,np.inf),(0,np.inf)])\n",
        "X = RandomWalkMetropolisHastings(\n",
        "    initial_state=[0.05, 0.1, 0.01, -0.05, 0.1],\n",
        "    proposal_params=[0.05, 0.1, 0.01, 0.1, 0.1],\n",
        "    data=Price,\n",
        "    model=Merton(0.05, 0.1, 0.01, -0.05, 0.1),\n",
        "    limits=Merton_limits # Adjust the Merton model initialization if needed\n",
        ")\n",
        "def get_random_initial_state(limits):\n",
        "    return np.array([np.random.uniform(l[0], l[1]) for l in limits])\n",
        "bounds=[(-0.4,0.4),(0,0.4),(0,0.02),(-0.4,0.4),(0,0.4)]\n",
        "results=[]\n",
        "for l in np.arange(20):\n",
        "    state=get_random_initial_state(bounds)\n",
        "    X = RandomWalkMetropolisHastings(\n",
        "    initial_state=state,\n",
        "    proposal_params=[0.05, 0.1, 0.01, 0.1, 0.1],\n",
        "    data=Price,\n",
        "    model=Merton(*state),\n",
        "    limits=Merton_limits # Adjust the Merton model initialization if needed\n",
        ")\n",
        "    exit=X.run(1000)\n",
        "    results.append(exit)\n",
        "\n",
        "    \n",
        "best_exit=max(results,key=lambda x:x[0])\n",
        "print(best_exit)\n",
        "Model=Merton(*exit[1])\n",
        "P=Model.simulate_end(366,1/365)\n",
        "\n",
        "P=np.diff(np.log(np.array(P).transpose()))[0]\n",
        "plt.subplot(1,2,2)\n",
        "x,y,_=plt.hist(Price[\"0\"],bins=100)\n",
        "\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.hist(P,bins=100)\n",
        "plt.xlim(min(y),max(y))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rand_kou_params():\n",
        "    mu = np.random.uniform(-0.1, 0.1)\n",
        "    sigma = np.random.uniform(0.01, 0.2)\n",
        "    lambda_ = np.random.uniform(0.01, 0.1)\n",
        "    p = np.random.uniform(0.1, 0.9)\n",
        "    eta1 = np.random.uniform(0.01, 0.1)\n",
        "    eta2 = np.random.uniform(0.01, 0.1)\n",
        "    return [mu, sigma, lambda_, p, eta1, eta2]\n",
        "Kou_limits=np.array([[0.01,np.inf],[0.01,np.inf],[0.01,np.inf],[0,1],[0.01,np.inf],[0.01,np.inf]])\n",
        "results=[]\n",
        "\n",
        "for l in np.arange(15):\n",
        "    Y=RandomWalkMetropolisHastings(\n",
        "        initial_state=rand_kou_params(),\n",
        "        proposal_params=[0.01, 0.05, 0.001, 0.05, 0.03, 0.05],\n",
        "        data=Price,\n",
        "        model=Kou(0.05, 0.1, 0.01, 0.5, 0.1, 0.1),\n",
        "        limits=Kou_limits  # Adjust the Kou model initialization if needed\n",
        "    )\n",
        "    Y.run(1000)\n",
        "    results.append(Y.max_likelihood,Y.max_state)\n",
        "    \n",
        "\n",
        "#Y.run(1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "L=results[np.argmax([x[0] for x in results])]\n",
        "L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import concurrent.futures\n",
        "def run_with_timeout(func, args=(), kwargs={}, timeout=5):\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        future = executor.submit(func, *args, **kwargs)\n",
        "        try:\n",
        "            result = future.result(timeout=timeout)\n",
        "            return result\n",
        "        except concurrent.futures.TimeoutError:\n",
        "            return \"Function call timed out\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rand_params():\n",
        "    return [np.random.uniform(10, 140), np.random.uniform(1, 25), np.random.uniform(1, 25), np.random.uniform(-3, 1.9), np.random.uniform(-0.1, 0.1)]\n",
        "CGMY_limits=np.array([[0,np.inf],[1,np.inf],[1,np.inf],[-np.inf,1.9],[-np.inf,np.inf]])\n",
        "results=[]\n",
        "for l in np.arange(15):\n",
        "    initial_params = rand_params()\n",
        "    CGMY_sim=RandomWalkMetropolisHastings(initial_state=initial_params,\n",
        "                                        proposal_params=[0.5,0.3,0.3,0.02,0.01],\n",
        "                                        data=Price,\n",
        "                                        model=CGMY(*initial_params,0.05),\n",
        "                                        limits=CGMY_limits,\n",
        "                                        special=0)\n",
        "    try:\n",
        "        x=run_with_timeout(CGMY_sim.run,args=(4000,), timeout=1)\n",
        "        results.append([CGMY_sim.max_likelihood,CGMY_sim.max_state])\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        continue\n",
        "    #CGMY_sim.run(4000)\n",
        "L=max(results,key=lambda x:x[0])\n",
        "model=CGMY(*L[1],0.05)\n",
        "P=model.simulate_end(366,1/365,100)\n",
        "P=np.diff(np.log(np.array(P).transpose()))[0]\n",
        "plt.subplot(1,2,2)\n",
        "x,y,_=plt.hist(Price[\"0\"],bins=100)\n",
        "plt.subplot(1,2,1)\n",
        "plt.hist(P,bins=100)\n",
        "plt.xlim(min(y),max(y))\n",
        "plt.show()\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "'numpy.ndarray' object is not callable",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[38], line 114\u001b[0m\n\u001b[0;32m    112\u001b[0m price_data\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAAPL.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    113\u001b[0m trainer \u001b[38;5;241m=\u001b[39m ModelTrainer(price_data)\n\u001b[1;32m--> 114\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_cgmy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain_merton()\n\u001b[0;32m    116\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain_kou()\n",
            "Cell \u001b[1;32mIn[38], line 27\u001b[0m, in \u001b[0;36mModelTrainer.train_cgmy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     25\u001b[0m CGMY_limits \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m0\u001b[39m, np\u001b[38;5;241m.\u001b[39minf], [\u001b[38;5;241m1\u001b[39m, np\u001b[38;5;241m.\u001b[39minf], [\u001b[38;5;241m1\u001b[39m, np\u001b[38;5;241m.\u001b[39minf], [\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, \u001b[38;5;241m1.9\u001b[39m], [\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, np\u001b[38;5;241m.\u001b[39minf]])\n\u001b[0;32m     26\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     28\u001b[0m     initial_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrand_params()\n\u001b[0;32m     29\u001b[0m     CGMY_sim \u001b[38;5;241m=\u001b[39m RandomWalkMetropolisHastings(\n\u001b[0;32m     30\u001b[0m         initial_state\u001b[38;5;241m=\u001b[39minitial_params,\n\u001b[0;32m     31\u001b[0m         proposal_params\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.02\u001b[39m, \u001b[38;5;241m0.01\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m         special\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     36\u001b[0m     )\n",
            "\u001b[1;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class ModelTrainer:\n",
        "    def __init__(self, price_data):\n",
        "        self.price_data = price_data\n",
        "        self.results = {}\n",
        "\n",
        "    def rand_params(self):\n",
        "        return [np.random.uniform(10, 140), np.random.uniform(1, 25), np.random.uniform(1, 25), np.random.uniform(-3, 1.9), np.random.uniform(-0.1, 0.1)]\n",
        "\n",
        "    def rand_kou_params(self):\n",
        "        mu = np.random.uniform(-0.1, 0.1)\n",
        "        sigma = np.random.uniform(0.01, 0.2)\n",
        "        lambda_ = np.random.uniform(0.01, 0.1)\n",
        "        p = np.random.uniform(0.1, 0.9)\n",
        "        eta1 = np.random.uniform(0.01, 0.1)\n",
        "        eta2 = np.random.uniform(0.01, 0.1)\n",
        "        return [mu, sigma, lambda_, p, eta1, eta2]\n",
        "\n",
        "    def get_random_initial_state(self, limits):\n",
        "        return np.array([np.random.uniform(l[0], l[1]) for l in limits])\n",
        "\n",
        "    def train_cgmy(self):\n",
        "        CGMY_limits = np.array([[0, np.inf], [1, np.inf], [1, np.inf], [-np.inf, 1.9], [-np.inf, np.inf]])\n",
        "        results = []\n",
        "        for _ in range(15):\n",
        "            initial_params = self.rand_params()\n",
        "            CGMY_sim = RandomWalkMetropolisHastings(\n",
        "                initial_state=initial_params,\n",
        "                proposal_params=[0.5, 0.3, 0.3, 0.02, 0.01],\n",
        "                data=self.price_data,\n",
        "                model=CGMY(*initial_params, 0.05),\n",
        "                limits=CGMY_limits,\n",
        "                special=0\n",
        "            )\n",
        "            try:\n",
        "                x = run_with_timeout(CGMY_sim.run, args=(4000,), timeout=1)\n",
        "                results.append([CGMY_sim.max_likelihood, CGMY_sim.max_state])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "                continue\n",
        "\n",
        "        best_result = max(results, key=lambda x: x[0])\n",
        "        self.results['CGMY'] = best_result\n",
        "        self.visualize_model('CGMY', best_result)\n",
        "\n",
        "    def train_merton(self):\n",
        "        Merton_limits = np.array([(0, np.inf), (0, np.inf), (0, np.inf), (-np.inf, np.inf), (0, np.inf)])\n",
        "        bounds = [(-0.4, 0.4), (0, 0.4), (0, 0.02), (-0.4, 0.4), (0, 0.4)]\n",
        "        results = []\n",
        "        for _ in range(20):\n",
        "            state = self.get_random_initial_state(bounds)\n",
        "            X = RandomWalkMetropolisHastings(\n",
        "                initial_state=state,\n",
        "                proposal_params=[0.05, 0.1, 0.01, 0.1, 0.1],\n",
        "                data=self.price_data,\n",
        "                model=Merton(*state),\n",
        "                limits=Merton_limits\n",
        "            )\n",
        "            exit = X.run(1000)\n",
        "            results.append(exit)\n",
        "\n",
        "        best_exit = max(results, key=lambda x: x[0])\n",
        "        self.results['Merton'] = best_exit\n",
        "        self.visualize_model('Merton', best_exit)\n",
        "\n",
        "    def train_kou(self):\n",
        "        Kou_limits = np.array([[0.01, np.inf], [0.01, np.inf], [0.01, np.inf], [0, 1], [0.01, np.inf], [0.01, np.inf]])\n",
        "        results = []\n",
        "        for _ in range(15):\n",
        "            Y = RandomWalkMetropolisHastings(\n",
        "                initial_state=self.rand_kou_params(),\n",
        "                proposal_params=[0.01, 0.05, 0.001, 0.05, 0.03, 0.05],\n",
        "                data=self.price_data,\n",
        "                model=Kou(0.05, 0.1, 0.01, 0.5, 0.1, 0.1),\n",
        "                limits=Kou_limits\n",
        "            )\n",
        "            Y.run(1000)\n",
        "            results.append((Y.max_likelihood, Y.max_state))\n",
        "\n",
        "        best_result = max(results, key=lambda x: x[0])\n",
        "        self.results['Kou'] = best_result\n",
        "        self.visualize_model('Kou', best_result)\n",
        "\n",
        "    def visualize_model(self, model_name, best_result):\n",
        "        if model_name == 'CGMY':\n",
        "            model = CGMY(*best_result[1], 0.05)\n",
        "        elif model_name == 'Merton':\n",
        "            model = Merton(*best_result[1])\n",
        "        elif model_name == 'Kou':\n",
        "            model = Kou(*best_result[1])\n",
        "\n",
        "        P = model.simulate_end(366, 1/365, 100)\n",
        "        P = np.diff(np.log(np.array(P).transpose()))[0]\n",
        "        \n",
        "        plt.figure(figsize=(12, 6))\n",
        "        \n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.hist(P, bins=100)\n",
        "        plt.title(f'{model_name} Model Simulated Log Returns')\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        x, y, _ = plt.hist(self.price_data[\"0\"], bins=100)\n",
        "        plt.title(f'{model_name} Model Historical Log Returns')\n",
        "\n",
        "        plt.xlim(min(y), max(y))\n",
        "        plt.show()\n",
        "\n",
        "# Usage example:\n",
        "# price_data = load_your_price_data_function()\n",
        "price_data=pd.read_csv(\"AAPL.csv\")\n",
        "trainer = ModelTrainer(price_data)\n",
        "trainer.train_cgmy()\n",
        "trainer.train_merton()\n",
        "trainer.train_kou()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
